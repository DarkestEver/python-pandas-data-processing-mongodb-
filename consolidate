import os
import re            
import pandas as pd
import pandasql as pdsql
import time
from datetime import datetime
import psycopg2
from sqlalchemy import create_engine
import json
from pprint import pprint


with open('config.json') as data_file:    
    data = json.load(data_file)
    



#manual system start #
curr_dir = data["current_directory"]
folder_path = data["folder_to_scan_path"]
log_file_path = data["log_sql_query_path"]
path_mapping_col = data["path_mapping_file"]
log_detailed_file_info = data["log_detailed_file_info"]  + str(datetime.now().strftime('%Y-%m-%d_%H-%M')) +'.csv'
#manual system end #


pysql = lambda q: pdsql.sqldf(q, globals())
def check_mandate_email(ls_to_chk, ls_in_to_chk, operator = 'and'):
    count = 0
    if operator == 'or':
        for x in ls_to_chk:
            if x in ls_in_to_chk:
                count = count + 1
        if count > 0:
            return  True
        else:
            return False    
            
    if operator == 'and':
        for x in ls_to_chk:
            if x in ls_in_to_chk:
                count = count + 1
        if count == len(ls_to_chk):
            return True
        else:
            return False

#get all files from directory
def get_filepaths(directory):
    file_paths = [] 
    for root, directories, files in os.walk(directory):
        for filename in files:
            filepath = os.path.join(root, filename)
            file_paths.append(filepath)
    return file_paths

# read mapping csv file and return dataframe of it
def read_mapping_csv(path):
    df_mapping = pd.read_csv(path_mapping_col,encoding='ISO_8859_5')
    df_mapping = df_mapping.fillna('')
    df_mapping = df_mapping.apply(lambda x: x.astype(str).str.lower())
    return   df_mapping

#extract alphanumeric from string and convert into lower case
def str_to_lcase_alphanum(strng):
   a = "".join(i for i in strng if ord(i)<128)
   return ("".join(re.findall("\w", a))).lower()

#return the dataframe of matching value[[ key, value],[ key, value],[ key, value]]
def get_matched_col(ls_file_header, df_mapping_col):
    df_mapped = pd.DataFrame()
    for str_hd_col in ls_file_header:
        for mapping_col_name in df_mapping_col:
            ls_mapped = []
            c = str_to_lcase_alphanum(str_hd_col)
            if len(df_mapping.loc[df_mapping[mapping_col_name] == c ]) > 0:
               ls_mapped.append([mapping_col_name ,  str_hd_col])
               df_mapped = df_mapped.append(ls_mapped)
    return df_mapped
# concatenate the matching columns in sql select column format
def generate_sql(lf_mapping_col,df_mapped ):
    str_col = ''
    for x in lf_mapping_col:
        df_vals = df_mapped.loc[df_mapped[0] == x ]
        len_df_vals = len(df_vals)
        if len_df_vals == 0:
            str_col =  'NULL as ' + x + ',' + str_col
        if len_df_vals == 1:
            str_col = '`' +  df_vals[1][0] + '` as ' + x + ',' + str_col
        if len_df_vals > 1:
            str_temp = ''
            for i in df_vals[1][0]:
                str_temp = '`'+ i + '` || ":" || ' + str_temp 
            str_temp = str_temp[:-10]
            str_col = str_temp + ' as ' + x + ',' + str_col
    str_col = str_col.rstrip(",")
    return str_col

def file_time(file,typ='c'):
    if typ=='c':
        return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(os.path.getctime(file)))
    if typ=='m':
        return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(os.path.getmtime(file)))
    
def remove_non_ascii(text):
     return ''.join(i for i in text if ord(i)<128)

def file_filtering(df_data,filename,sheetname=''):
    ls_c=[]
    ls_col =  [x.lower() for x in  list(df_data.columns)]
    len_ls_col = len(ls_col)
    if len_ls_col >  3 :
        ls_filesht = [filename, sheetname,'ok']
        ls_filesht.extend(ls_col)
        ls_c.extend(ls_filesht)
    else:
        ls_c.extend([filename,sheetname,'not valid'] )
    return ls_c
 
def write_log(log_file_path, text):
    with open(log_file_path, "w") as text_file:
        text_file.write(text)

df_header_in_row_format = pd.DataFrame()
df_file_info =  pd.DataFrame()
log_sql_quer = ''


df_mapping = read_mapping_csv(path_mapping_col)
df_mapping = df_mapping.fillna('')
df_mapping = df_mapping.replace({'[^A-Za-z0-9]': ''}, regex=True)
df_mapping = df_mapping.apply(lambda x: x.astype(str).str.lower())
lf_mapping_col = df_mapping.columns

engine = create_engine("postgresql://postgres:root@localhost:5432/postgres")
# call function to get all files into list
#"E:\\keshav docs\\OneDrive\\Projects\\sample data\\OneDrive_1_7-2-2017\\01 - Excel"
full_file_paths = get_filepaths(folder_path)
# Processing filename and sheet name(in case of excel)
for filename in full_file_paths:   
    try:
        ls_file_col_name = []
        if filename.lower().endswith(('.xls', '.xlsx')) == True:
            xl_fil = pd.ExcelFile(filename)
            sheetnames = xl_fil.sheet_names
            for shtname in sheetnames:
                df_file_data = xl_fil.parse(shtname)
                ls_file_col_name = file_filtering(df_file_data,filename,shtname)
                if ls_file_col_name[2]  == 'ok':
                    df_file_data = df_file_data.fillna('')
                    ls_file_header = list(df_file_data.columns) #ls_file_header raw file header in list
                    df_mapped = get_matched_col(ls_file_header, lf_mapping_col)
                    strng = generate_sql(lf_mapping_col,df_mapped )
                    log_sql_quer = log_sql_quer + '\n\n---------------------------------------\n'+ filename +' -- '+ shtname+'\n' + strng
                    write_log(log_file_path,log_sql_quer)
                    print(strng)
                    print('---------------------------------')
    
                    sql_str = 'select '+ strng +' from df_file_data'
                    df_final = pysql(sql_str)
                    
                    #extra fields
                    #time_file_created
                    #time_file_modified
                    #filename
                    str_file_created_date = file_time(filename, 'c')
                    str_file_modified_date =  file_time(filename, 'm')
                    
                    df_final['time_file_created'] = str_file_created_date
                    df_final['time_file_modified'] =   str_file_modified_date
                    df_final['filename'] = filename
                    print(filename)
                    
                    df_final.to_sql('db_table4', engine, if_exists='append')
                    #add file created date to dataframe
                    df_file_info  = df_file_info.append([ls_file_col_name]) 
                    df_file_info.to_csv(log_detailed_file_info)
                else:
                    ls_temp = [filename,'','file not supported']
                    df_file_info = df_file_info.append([ls_temp])
                    df_file_info.to_csv(log_detailed_file_info)
    except Exception as e:
        ls_temp = [filename,'',str(e)]
        print(str(e))
        df_file_info = df_file_info.append([ls_temp])
        df_file_info.to_csv(log_detailed_file_info)
df_file_info = []
